{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be9f5dc6",
   "metadata": {},
   "source": [
    "#### Number of unique solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c48fda16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ly/DataDistillation/results/steering/Qwen2.5-Math-1.5B-Instruct$/olympiadbench/temperature-sampling-fixed/steer-algor1-ver3_n8_olympiadbench_steern500-calpha-k10-temp0.8-after_raw.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows: 100%|██████████| 675/675 [09:34<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall average unique responses per problem: 4.36 (±2.32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  10%|█         | 1/10 [09:34<1:26:12, 574.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ly/DataDistillation/results/steering/Qwen2.5-Math-1.5B-Instruct$/olympiadbench/temperature-sampling-fixed/steer-algor1-ver3_n8_olympiadbench_steern500-calpha-k1-temp0.4-after_raw.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows: 100%|██████████| 675/675 [09:01<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall average unique responses per problem: 3.99 (±2.19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  20%|██        | 2/10 [18:36<1:14:03, 555.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ly/DataDistillation/results/steering/Qwen2.5-Math-1.5B-Instruct$/olympiadbench/temperature-sampling-fixed/steer-algor1-ver3_n8_olympiadbench_steern500-calpha-k10-temp0.2-after_raw.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows: 100%|██████████| 675/675 [09:13<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall average unique responses per problem: 3.65 (±2.04)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  30%|███       | 3/10 [27:50<1:04:42, 554.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ly/DataDistillation/results/steering/Qwen2.5-Math-1.5B-Instruct$/olympiadbench/temperature-sampling-fixed/steer-algor1-ver3_n8_olympiadbench_steern500-calpha-k1-temp0.8-after_raw.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows: 100%|██████████| 675/675 [09:02<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall average unique responses per problem: 4.28 (±2.31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  40%|████      | 4/10 [36:53<55:00, 550.09s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ly/DataDistillation/results/steering/Qwen2.5-Math-1.5B-Instruct$/olympiadbench/temperature-sampling-fixed/steer-algor1-ver3_n8_olympiadbench_steern500-calpha-k1-temp0.2-after_raw.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows: 100%|██████████| 675/675 [10:09<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall average unique responses per problem: 3.67 (±2.04)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  50%|█████     | 5/10 [47:03<47:38, 571.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ly/DataDistillation/results/steering/Qwen2.5-Math-1.5B-Instruct$/olympiadbench/temperature-sampling-fixed/steer-algor1-ver3_n8_olympiadbench_steern500-calpha-k1-temp1.0-after_raw.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows: 100%|██████████| 675/675 [10:34<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall average unique responses per problem: 4.59 (±2.34)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  60%|██████    | 6/10 [57:38<39:32, 593.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ly/DataDistillation/results/steering/Qwen2.5-Math-1.5B-Instruct$/olympiadbench/temperature-sampling-fixed/steer-algor1-ver3_n8_olympiadbench_steern500-calpha-k10-temp1.0-after_raw.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows: 100%|██████████| 675/675 [09:39<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall average unique responses per problem: 4.53 (±2.35)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  70%|███████   | 7/10 [1:07:18<29:26, 588.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ly/DataDistillation/results/steering/Qwen2.5-Math-1.5B-Instruct$/olympiadbench/temperature-sampling-fixed/steer-algor1-ver3_n8_olympiadbench_steern500-calpha-k10-temp0.6-after_raw.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows: 100%|██████████| 675/675 [09:08<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall average unique responses per problem: 4.16 (±2.26)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  80%|████████  | 8/10 [1:16:27<19:12, 576.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ly/DataDistillation/results/steering/Qwen2.5-Math-1.5B-Instruct$/olympiadbench/temperature-sampling-fixed/steer-algor1-ver3_n8_olympiadbench_steern500-calpha-k1-temp0.6-after_raw.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows: 100%|██████████| 675/675 [09:30<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall average unique responses per problem: 4.10 (±2.24)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  90%|█████████ | 9/10 [1:25:58<09:34, 574.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ly/DataDistillation/results/steering/Qwen2.5-Math-1.5B-Instruct$/olympiadbench/temperature-sampling-fixed/steer-algor1-ver3_n8_olympiadbench_steern500-calpha-k10-temp0.4-after_raw.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows: 100%|██████████| 675/675 [08:55<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall average unique responses per problem: 3.92 (±2.19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 10/10 [1:34:54<00:00, 569.45s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the client (new syntax)\n",
    "client = OpenAI(api_key=OPEN_API_KEY)  # or pass key directly\n",
    "\n",
    "def create_prompt(problem, responses):\n",
    "    return f\"\"\"You are given a math reasoning problem and a list of responses generated by a model.\n",
    "\n",
    "    Your task is to count how many **unique** responses there are.\n",
    "\n",
    "    Two responses are considered different if they use different:\n",
    "    - Mathematical strategies\n",
    "    - Solution steps\n",
    "    - Logical approach\n",
    "    - Structure of reasoning\n",
    "\n",
    "    ### Problem:\n",
    "    {problem}\n",
    "\n",
    "    ### Responses:\n",
    "    {responses}\n",
    "\n",
    "    ### Instruction:\n",
    "    Output **only** the number of unique responses as an integer.  \n",
    "    Do **not** include any explanation, text, or symbols — just the number.\n",
    "\n",
    "    Example output: `3`\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "def call_gpt(prompt):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4.1-mini\",  # Or \"gpt-4.1-mini\" if available\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.0,\n",
    "        )\n",
    "        reply = response.choices[0].message.content.strip()\n",
    "        # print(f\"Reply: {reply}\")\n",
    "        score = int(reply.split()[0])  # naive float parsing\n",
    "        return score\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing prompt: {e}\")\n",
    "        return None\n",
    "\n",
    "# Path setup\n",
    "dir_path = \"/home/ly/DataDistillation/results/steering/Qwen2.5-Math-1.5B-Instruct$/olympiadbench/temperature-sampling-fixed\"\n",
    "pkl_files = []\n",
    "for root, dirs, files in os.walk(dir_path):\n",
    "    for filename in files:\n",
    "        if filename.endswith(\".pkl\"):\n",
    "            pkl_files.append(os.path.join(root, filename))\n",
    "\n",
    "# Main loop\n",
    "overall_scores = []\n",
    "\n",
    "for file_path in tqdm(pkl_files, desc=\"Processing files\"):\n",
    "    print(file_path)\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    results = []\n",
    "\n",
    "    for row in tqdm(data.get(\"results\", []), desc=\"Processing rows\", total=len(data.get(\"results\", []))):\n",
    "        problem = row.get(\"problem\", \"\")\n",
    "        response = row.get(\"responses\", \"\")\n",
    "        prompt = create_prompt(problem, response)\n",
    "        score = call_gpt(prompt)\n",
    "\n",
    "        results.append({\n",
    "            \"file\": os.path.basename(file_path),\n",
    "            \"problem\": problem,\n",
    "            \"response\": response,\n",
    "            \"score\": score,\n",
    "        })\n",
    "    scores = [r[\"score\"] for r in results]\n",
    "    mean_score = np.mean(scores)\n",
    "    std_score = np.std(scores)\n",
    "    print(f\"\\nOverall average unique responses per problem: {mean_score:.2f} (±{std_score:.2f})\")\n",
    "    df = pd.DataFrame(results)\n",
    "    filename = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    overall_scores.append(f\"\\n{filename}\")\n",
    "    overall_scores.append(f\"\\nOverall average unique responses per problem: {mean_score:.2f} (±{std_score:.2f})\")\n",
    "    df.to_csv(f\"/home/ly/DataDistillation/results/steering/Qwen2.5-Math-1.5B-Instruct$/olympiadbench/temperature-sampling-fixed/unique_responses_{filename}.csv\", index=False)\n",
    "  \n",
    "with open(f\"/home/ly/DataDistillation/results/steering/Qwen2.5-Math-1.5B-Instruct$/olympiadbench/temperature-sampling-fixed/unique_responses.txt\", \"w\") as f:\n",
    "    f.writelines(overall_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66774078",
   "metadata": {},
   "source": [
    "#### Diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705976d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ly/DataDistillation/results/steering/Qwen2.5-1.5B$/olympiadbench/temperature-sampling-fixed/new/steer-algor1-ver3_n8_olympiadbench_steern500-calpha-k10-temp1.0-after_raw.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the client (new syntax)\n",
    "client = OpenAI(api_key=OPEN_API_KEY)  # or pass key directly\n",
    "\n",
    "def create_prompt(problem, responses):\n",
    "    return f'''You are given a math reasoning problem and a list of different responses (solutions) generated by a model.\n",
    "        Your task is to assign a float score from 0 to 1.0 that reflects the **diversity of reasoning and approaches** among the responses.\n",
    "        Consider differences in:\n",
    "        - Mathematical strategies\n",
    "        - Solution steps\n",
    "        - Structural approach\n",
    "        - Logical of reasoning\n",
    "\n",
    "        ### Problem:\n",
    "        {problem}\n",
    "\n",
    "        ### Responses:\n",
    "        {responses}\n",
    "\n",
    "        ### Instruction:\n",
    "        Output **only** a float number between 0 and 1.0 (inclusive), rounded to two decimal places.  \n",
    "        Do **not** include any explanation, symbols, or text — only the score.\n",
    "\n",
    "        Example output: `0.75`\n",
    "        '''\n",
    "\n",
    "def call_gpt(prompt):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4.1-mini\",  # Or \"gpt-4.1-mini\" if available\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.0,\n",
    "        )\n",
    "        reply = response.choices[0].message.content.strip()\n",
    "        # print(f\"Prompt: {prompt}\\nReply: {reply}\")\n",
    "        score = float(reply.split()[0])  # naive float parsing\n",
    "        return score\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing prompt: {e}\")\n",
    "        return None\n",
    "\n",
    "# Path setup\n",
    "dir_path = \"/home/ly/DataDistillation/results/steering/Qwen2.5-1.5B$/olympiadbench/temperature-sampling-fixed/new\"\n",
    "pkl_files = []\n",
    "for root, dirs, files in os.walk(dir_path):\n",
    "    for filename in files:\n",
    "        if filename.endswith(\".pkl\"):\n",
    "            pkl_files.append(os.path.join(root, filename))\n",
    "\n",
    "# Main loop\n",
    "overall_scores = []\n",
    "for file_path in tqdm(pkl_files, desc=\"Processing files\"):\n",
    "    print(file_path)\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    results = []\n",
    "    for row in tqdm(data.get(\"results\", []), desc=\"Processing rows\", total=len(data.get(\"results\", []))):\n",
    "        problem = row.get(\"problem\", \"\")\n",
    "        response = row.get(\"responses\", \"\")\n",
    "        prompt = create_prompt(problem, response)\n",
    "        score = call_gpt(prompt)\n",
    "\n",
    "        results.append({\n",
    "            \"file\": os.path.basename(file_path),\n",
    "            \"problem\": problem,\n",
    "            \"response\": response,\n",
    "            \"score\": score,\n",
    "        })\n",
    "        \n",
    "    scores = [r[\"score\"] for r in results]\n",
    "    mean_score = np.mean(scores)\n",
    "    std_score = np.std(scores)\n",
    "    print(f\"\\nOverall average diversity score per problem: {mean_score:.2f} (±{std_score:.2f})\")\n",
    "    df = pd.DataFrame(results)\n",
    "    filename = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    overall_scores.append(f\"\\n{filename}\")\n",
    "    overall_scores.append(f\"\\nOverall average diversity score per problem: {mean_score:.2f} (±{std_score:.2f})\")\n",
    "    df.to_csv(f\"/home/ly/DataDistillation/results/steering/Qwen2.5-1.5B$/olympiadbench/temperature-sampling-fixed/new/diversity_score_{filename}.csv\", index=False)\n",
    "  \n",
    "with open(f\"/home/ly/DataDistillation/results/steering/Qwen2.5-1.5B$/olympiadbench/temperature-sampling-fixed/new/diversity_score.txt\", \"w\") as f:\n",
    "    f.writelines(overall_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac49077b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "dc8dc45a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.05674323552038686)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"/home/ly/DataDistillation/results/steering/Qwen2.5-Math-1.5B-Instruct$/olympiadbench/temperature-sampling-fixed/diversity_score_steer-algor1-ver3_n8_olympiadbench_steern500-calpha-k10-temp0.2-after_raw.csv\"\n",
    "import pandas as pd\n",
    "df = pd.read_csv(file_path)\n",
    "df['score'].var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f0ee4460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diversity_score_steer-algor1-ver3_n8_olympiadbench_steern500-calpha-k0.0001-temp0.6-before_raw.csv: Variance = 0.0567\n",
      "diversity_score_steer-algor1-ver3_n8_olympiadbench_steern500-calpha-k0.0001-temp0.4-before_raw.csv: Variance = 0.0549\n",
      "diversity_score_steer-algor1-ver3_n8_olympiadbench_steern500-calpha-k10-temp0.2-before_raw.csv: Variance = 0.0477\n",
      "unique_responses_steer-algor1-ver3_n8_olympiadbench_steern500-calpha-k10-temp0.2-before_raw.csv: Variance = 2.2064\n",
      "unique_responses_steer-algor1-ver3_n8_olympiadbench_steern500-calpha-k0.00001-temp1.0-before_raw.csv: Variance = 1.6107\n",
      "unique_responses_steer-algor1-ver3_n8_olympiadbench_steern500-calpha-k0.0001-temp0.6-before_raw.csv: Variance = 1.6748\n",
      "unique_responses_steer-algor1-ver3_n8_olympiadbench_steern500-calpha-k0.0001-temp0.4-before_raw.csv: Variance = 1.9897\n",
      "diversity_score_steer-algor1-ver3_n8_olympiadbench_steern500-calpha-k0.00001-temp0.8-before_raw.csv: Variance = 0.0611\n",
      "diversity_score_steer-algor1-ver3_n8_olympiadbench_steern500-calpha-k0.00001-temp1.0-before_raw.csv: Variance = 0.0592\n",
      "unique_responses_steer-algor1-ver3_n8_olympiadbench_steern500-calpha-k0.00001-temp0.8-before_raw.csv: Variance = 1.5251\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Đường dẫn thư mục chứa các file CSV\n",
    "folder_path = \"/home/ly/DataDistillation/results/steering/Qwen2.5-1.5B$/olympiadbench/temperature-sampling/before\"\n",
    "\n",
    "# Lặp qua tất cả các file CSV trong thư mục\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "\n",
    "            # Chuyển 'score' sang số nếu cần và bỏ NaN\n",
    "            df['score'] = pd.to_numeric(df['score'], errors='coerce')\n",
    "            variance = df['score'].dropna().var()\n",
    "\n",
    "            print(f\"{filename}: Variance = {variance:.4f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Lỗi khi xử lý {filename}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c266ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
